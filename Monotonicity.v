Require Export RelDefinitions.
Require Export RelOperators.
Require Export Relators.
Require Import Delay.

(** ** The [monotonicity] tactic *)

(** The purpose of the [monotonicity] tactic is to automatically
  select and apply a theorem of the form [Monotonic ?m ?R] in order to
  make progress when the goal is an applied relation. Compared with
  setoid rewriting, [monotonicity] is less powerful, but more direct
  and simple. This means it is easier to debug, and it can seamlessly
  handle dependent types and heterogenous relations. *)

(** *** Truncating applications *)

(** The search is at first guided by the left-hand side term, so that
  if the goal has the form [?R (?f ?x1 ?x2 ?x3 ... ?xn) ?y], we will
  seek a [Related] instance for some prefix [f x1 ... xk]. This allows
  both [R] and [y] to be existential variables, which is required in
  particular by the [transport] tactic.

  However, peeling off the [xi]s one by one and conducting a
  full-blown search at every step is very time-consuming. To deal with
  this issue we narrow down the search to (in this order):
    - the whole application [f x1 ... xk];
    - prefixes constructed from user-declared [Params] instances;
    - the head term [f] alone.

  In the following we define some tactics and classes to implement
  this search process. *)

(** [ApplicationHead] finds the head term [f] for an application [m]. *)

Ltac application_head m f :=
  lazymatch m with
    | ?m' _ => application_head m' f
    | _ => unify m f
  end.

Class ApplicationHead {A B} (m: A) (f: B).

Hint Extern 1 (ApplicationHead ?m ?f) =>
  application_head m f; constructor : typeclass_instances.

(** [RemoveParams] drops some arguments from the application [m] so
  that the result [f] expects [n] parameters. We are careful to skip
  an appropriate number of parameters when the type of term indicates
  that it is already a partial application. Note that we need to make
  sure we "open up" types such as [subrel] to expose the product,
  accomplished here by using [eval cbv]. *)

Ltac remove_params m n f :=
  let rec remove m n :=
    lazymatch n with
      | S ?n' =>
        lazymatch m with
          | ?m' _ => remove m' n'
        end
      | O => unify m f
    end in
  let rec remove_from_partial m t n :=
    let t := eval cbv in t in
    lazymatch t with
      | forall x, ?t' =>
        lazymatch n with
          | S ?n' => remove_from_partial m t' n'
        end
      | _ =>
        remove m n
    end in
  let t := type of m in
  remove_from_partial m t n.

Class RemoveParams {A B} (m: A) (n: nat) (f: B).

Hint Extern 1 (RemoveParams ?m ?n ?f) =>
  remove_params m n f; constructor : typeclass_instances.

(** With these, we can define [CandidatePrefix m f], which serves as
  the source of possible prefixes [f] of the application [m]. *)

Class CandidatePrefix {A B} (m: A) (f: B).

Global Instance candidate_prefix_self {A} (m: A):
  CandidatePrefix m m | 10.

Global Instance candidate_prefix_params {A B C} (m: A) (h: B) (n: nat) (f: C):
  ApplicationHead m h ->
  Params h n ->
  RemoveParams m n f ->
  CandidatePrefix m f | 20.

Global Instance candidate_prefix_head {A B} (m: A) (h: B):
  ApplicationHead m h ->
  CandidatePrefix m h | 30.

(** *** Selecting a relational property *)

Class CandidateProperty {A B} (R: rel A B) m n (Q: Prop) :=
  candidate_related: R m n.

(** We first attempt to use any matching hypothesis. This takes
  priority and bypasses any [Params] declaration. We assume that we
  will always want such hypotheses to be used, at least when the left-
  or right-hand side matches exactly. There is a possibility that this
  ends up being too broad for some applications, for which we'll want
  to restrict ourselves to [Related] instances explicitely defined by
  the user. If this turns out to be the case, we can introduce an
  intermediate class with more parameters to control the sources of
  the relational properties we use, and perhaps have some kind of
  normalization process akin to what is done in [Coq.Classes.Morphisms].

  We don't hesitate to instantiate evars in the goal or hypothesis; if
  the types or skeletons are compatible this is likely what we want.
  In one practical case where this is needed, my hypothesis is
  something like [R (f ?x1 ?y1 42) (f ?x2 ?y2 24)], and I want
  [?x1], [?x2], [?y1], [?y2] to be matched against the goal. In case
  the use of [unify] below is too broad, we could develop a strategy
  whereby at least one of the head terms [f], [g] should match exactly.

  We also consider the possibility that the relation's arguments may
  be flipped in the hypothesis, compared to the goal, when the
  relation is of the form (or can be instantiated to) [flip _].
  In that case [flip_relim] will allow us to use the property.
  This is especially common in the course of solving a goal of the
  form [(R --> R') f g], or goals generated by the setoid rewriting
  system of the form [Proper (?R1 ==> ... ==> ?Rn ==> flip impl)],
  and where the [?Ri]s will generally need to be instantiated as
  [flip ?Ri']. We do not pursue a similar strategy when looking up
  candidates from the typeclass instance database, because we expect
  the user to normalize such properties before they declare them, for
  example declare an instance of [Related (R1 ++> R2 --> R3) g f]
  rather than an instance of [Related (R1 --> R2 ++> flip R3) f g].

  Note that it is important that we reduce the goal to [?R ?m ?n]
  before we use [eexact]: if the relation in the hypothesis is an
  existential variable, we don't want unified against
  [CandidateProperty _ _ _ (_ ?m ?n)]. *)

Lemma unflip_context_candidate {A B} (R: rel A B) x y : flip R y x -> R x y.
Proof.
  firstorder.
Qed.

Ltac context_candidate :=
  let rec is_prefix f m :=
    first
      [ unify f m
      | lazymatch m with ?n _ => is_prefix f n end ] in
  let rec is_prefixable f m :=
    first
      [ is_evar f
      | is_evar m
      | unify f m
      | lazymatch m with ?n _ => is_prefixable f n end ] in
  match goal with
    | H: _ ?f ?g |- @CandidateProperty ?A ?B ?R ?x ?y (_ ?m ?n) =>
      red;
      first
        [ is_prefix f m; is_prefixable g n
        | is_prefix g n; is_prefixable f m
        | is_prefix g m; is_prefixable f n;
          apply (@unflip_context_candidate A B R x y)
        | is_prefix f n; is_prefixable g m;
          apply (@unflip_context_candidate A B R x y)];
      eexact H
  end.

Hint Extern 1 (CandidateProperty _ _ _ _) =>
  context_candidate : typeclass_instances.

(** After we've tried the relevant hypotheses, we use [Related]
  instances as described above. *)

Lemma candidate_l {A B GA GB} (R: rel A B) f g (QR: rel GA GB) m n:
  CandidatePrefix m f ->
  Related f g R ->
  CandidateProperty R f g (QR m n).
Proof.
  firstorder.
Qed.

Hint Extern 2 (CandidateProperty _ _ _ (?QR ?m ?n)) =>
  not_evar m; eapply candidate_l : typeclass_instances.

Lemma candidate_r {A B QA QB} (R: rel A B) f g (QR: rel QA QB) m n:
  CandidatePrefix n g ->
  Related f g R ->
  CandidateProperty R f g (QR m n).
Proof.
  firstorder.
Qed.

Hint Extern 3 (CandidateProperty _ _ _ (?QR ?m ?n)) =>
  not_evar n; eapply candidate_r : typeclass_instances.

(** *** Using [subrel] *)

(** It is not obvious at what point in the process [subrel] should be
  hooked in. One thing we crucially want to avoid is an open-ended
  [subrel] search enumerating all possibilities to be filtered later,
  with a high potential for exponential blow-up should the user be a
  little too liberal with the [subrel] instances they declare.

  Here I choose to have it kick in after a candidate property has been
  selected, and we know how to apply it to a goal. Then we use
  [subrel] to bridge any gap between that goal and the actual one,
  through the [RImpl] class below.

  This is a conservative solution which precludes many interesting
  usages of [subrel]. For instance, suppose we have a relational
  property alogn the lines of [Monotonic f ((R1 ++> R1) ∩ (R2 ++> R2))].
  We would want to be able to use it to show that [f] preserve [R1] or
  [R2] individually (because [subrel (R1 ++> R1) ((R1 ++> R1) ∩ (R2
  ++> R2))], but also together (because [subrel (R1 ∩ R2 ++> R1 ∩ R2)
  ((R1 ++> R1) ∩ (R2 ++> R2))]). This cannot be done using this
  approach, which does not act on the relational property itself but
  only the goal we're attempting to prove.

  Perhaps in the future we can extend this by acting at the level of
  [RElim]. In any case, we should provide explicit guidelines for when
  to declare [subrel] instances, and how. *)

Class RImpl (P Q: Prop): Prop :=
  rimpl: P -> Q.

(** While we give priority to [rimpl_refl] below, when it doesn't work
  we use [RAuto] to establish a [subrel] property. The [Monotonic]
  instances we declared alongside relators can be used conjunction
  with [Monotonicity] to break up [subrel] goals along the structure
  of the relations being considered. This may end up causing loops
  (especially in failure cases), so it may be necessary to add some
  flag in the context to prevent [subrel_related] from being used when
  discharging the [subrel] goals themselves. *)

Global Instance rimpl_refl {A B} (R : rel A B) m n:
  RImpl (R m n) (R m n).
Proof.
  firstorder.
Qed.

Global Instance rimpl_subrel {A B} (R R': rel A B) m n:
  NonDelayed (RAuto (subrel R R')) ->
  Unconvertible R R' ->
  RImpl (R m n) (R' m n).
Proof.
  firstorder.
Qed.

(** *** Main tactic *)

(** With these components, defining the [monotonicity] tactic is
  straightforward: identify a candidate property, then figure out a
  way to apply it to the goal [Q] using the [RElim] class. We first
  define a [Monotonicity] typeclass that captures this behavior with
  full backtracking ability. *)

Class Monotonicity (P Q: Prop): Prop :=
  monotonicity: P -> Q.

Global Instance apply_candidate {A B} (R: rel A B) m n P Q Q':
  CandidateProperty R m n Q ->
  RElim R m n P Q' ->
  RImpl Q' Q ->
  Monotonicity P Q.
Proof.
  firstorder.
Qed.

(** We also exploit [Reflexive] instances. A reflexive relation is one
  for which all elements are proper elements. Then reflexivity is a
  kind of general, nullary monotonicity property. In fact, in
  principle we should use [Reflexive] to declare a generic
  [Related] instance, and the instance below would follow. However,
  such instances end up polluting the resolution process and causing
  premature instanciations of existential variables.

  Instead, we only use the following instance as a last resort, and
  only to satisfy the goal directly (not in the search for relational
  properties). This allows us to insist the related terms be exactly
  identical, not just unifiable. *)

Global Instance reflexive_monotonicity {A} (R: rel A A) (m: A):
  NotEvar R ->
  Reflexive R ->
  Monotonicity True (R m m) | 10.
Proof.
  firstorder.
Qed.

(** The Ltac tactic simply applies [monotonicity]; typeclass
  resolution will do the rest. Note that using [apply] naively is too
  lenient because in a goal of type [A -> B], it will end up unifying
  [A] with [P] and [B] with [Q] instead of setting [Q := A -> B] and
  generating a new subgoal for [P] as expected. On the other hand,
  using [refine] directly is too restrictive because it will not unify
  the type of [monotonicity] against the goal if existential variables
  are present in one or the other. Hence we constrain apply just
  enough, so as to handle both of these cases. *)

Ltac monotonicity :=
  lazymatch goal with |- ?Q => apply (monotonicity (Q:=Q)) end;
  Delay.split_conjunction.

(** Another way to use [Monotonicity] is to hook it as an [RStep]
  instance. *)

Global Instance monotonicity_rstep {A B} (P: Prop) (R: rel A B) m n:
  Monotonicity P (R m n) ->
  RStep P (R m n) | 50.
Proof.
  firstorder.
Qed.
